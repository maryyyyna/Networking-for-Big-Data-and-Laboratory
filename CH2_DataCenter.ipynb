{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "16a7fd36",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fdcbad50",
   "metadata": {},
   "outputs": [],
   "source": [
    "tasks_dataframe = pd.read_csv(r\"C:\\Users\\Marina\\OneDrive\\Desktop\\Cell_a.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc99046d",
   "metadata": {},
   "source": [
    "# 1. Dataset Analysis ( aggiungere IMA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0a410231",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job_ID</th>\n",
       "      <th>Task_ID</th>\n",
       "      <th>Arrival_Time</th>\n",
       "      <th>CPU</th>\n",
       "      <th>Memory</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>375000667413</td>\n",
       "      <td>0</td>\n",
       "      <td>603026300</td>\n",
       "      <td>0.041851</td>\n",
       "      <td>0.001169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>375000669289</td>\n",
       "      <td>0</td>\n",
       "      <td>606413041</td>\n",
       "      <td>0.024968</td>\n",
       "      <td>0.001179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>375000670586</td>\n",
       "      <td>0</td>\n",
       "      <td>608994453</td>\n",
       "      <td>0.024176</td>\n",
       "      <td>0.001173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>375000670588</td>\n",
       "      <td>0</td>\n",
       "      <td>608994466</td>\n",
       "      <td>0.019552</td>\n",
       "      <td>0.001163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>375000670590</td>\n",
       "      <td>0</td>\n",
       "      <td>609042903</td>\n",
       "      <td>0.028044</td>\n",
       "      <td>0.001179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2329127</th>\n",
       "      <td>400465207745</td>\n",
       "      <td>0</td>\n",
       "      <td>2678935469565</td>\n",
       "      <td>0.004677</td>\n",
       "      <td>0.000067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2329128</th>\n",
       "      <td>400465219425</td>\n",
       "      <td>0</td>\n",
       "      <td>2678943690687</td>\n",
       "      <td>0.000343</td>\n",
       "      <td>0.000004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2329129</th>\n",
       "      <td>400465219425</td>\n",
       "      <td>1</td>\n",
       "      <td>2678943690687</td>\n",
       "      <td>0.000557</td>\n",
       "      <td>0.000004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2329130</th>\n",
       "      <td>400465256347</td>\n",
       "      <td>0</td>\n",
       "      <td>2678955330224</td>\n",
       "      <td>0.002459</td>\n",
       "      <td>0.000050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2329131</th>\n",
       "      <td>400465256349</td>\n",
       "      <td>0</td>\n",
       "      <td>2678955330235</td>\n",
       "      <td>0.004349</td>\n",
       "      <td>0.000052</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2282872 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               Job_ID  Task_ID   Arrival_Time       CPU    Memory\n",
       "0        375000667413        0      603026300  0.041851  0.001169\n",
       "1        375000669289        0      606413041  0.024968  0.001179\n",
       "2        375000670586        0      608994453  0.024176  0.001173\n",
       "3        375000670588        0      608994466  0.019552  0.001163\n",
       "4        375000670590        0      609042903  0.028044  0.001179\n",
       "...               ...      ...            ...       ...       ...\n",
       "2329127  400465207745        0  2678935469565  0.004677  0.000067\n",
       "2329128  400465219425        0  2678943690687  0.000343  0.000004\n",
       "2329129  400465219425        1  2678943690687  0.000557  0.000004\n",
       "2329130  400465256347        0  2678955330224  0.002459  0.000050\n",
       "2329131  400465256349        0  2678955330235  0.004349  0.000052\n",
       "\n",
       "[2282872 rows x 5 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Removing rows with CPU usage equal to 0 from the dataset\n",
    "cpu_usage = tasks_dataframe['CPU'] > 0\n",
    "tasks_dataframe = tasks_dataframe.drop(tasks_dataframe[~cpu_usage].index)\n",
    "tasks_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d3d928ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting the Arrival Time column from microseconds to seconds\n",
    "tasks_dataframe['Arrival_Time'] = tasks_dataframe['Arrival_Time'] / 1000000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab8a32c5",
   "metadata": {},
   "source": [
    "# 2. Algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60c922cb",
   "metadata": {},
   "source": [
    "$$ U_{n} = max{(0, U_{n−1} − T_{n})} + X_{n}, n ≥ 1 $$\n",
    "where:\n",
    "- U_0 = 0;\n",
    "- T_n is the inter-arrival time between arrival n − 1 and n;\n",
    "- X_n is the service time or the n-th arriving task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7377ba81",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import itertools\n",
    "\n",
    "class Task:\n",
    "    def __init__(self, job_id, task_id, arrival_time, cpu_usage, memory_usage):\n",
    "        self.job_id = job_id\n",
    "        self.task_id = task_id\n",
    "        self.arrival_time = arrival_time\n",
    "        self.cpu_usage = cpu_usage\n",
    "        self.memory_usage = memory_usage\n",
    "        self.completion_time = None\n",
    "        self.service_time = cpu_usage / 0.1\n",
    "\n",
    "    def __lt__(self, other):\n",
    "        # Compare tasks based on remaining service time\n",
    "        return self.cpu_usage < other.cpu_usage\n",
    "\n",
    "# Function to simulate baseline (LWL dispatching and FCFS scheduling)\n",
    "def calculate_completion_time_baseline(tasks, num_servers):\n",
    "    servers = [[] for _ in range(N)]  # List of servers, each server can have multiple tasks\n",
    "    unfinished_work = [0] *  N # Unfinished work for each server\n",
    "    inter_arrival_times = [0] * len(tasks)\n",
    "    task_completion_times = {}  # Dictionary to store completion time for each task\n",
    "    service_times = []\n",
    "    message_loads = 0\n",
    "    \n",
    "    for n in range(len(tasks)):\n",
    "        \n",
    "        # LWL DISPATCHING \n",
    "        available_servers = [i for i, server_tasks in enumerate(servers) if not server_tasks]  # Find servers with no tasks\n",
    "        if available_servers:\n",
    "            server_id = available_servers[0]  # Choose the first available server\n",
    "        else:\n",
    "            server_id = unfinished_work.index(min(unfinished_work))  # Find the server with the least unfinished work\n",
    "        \n",
    "        # FCFS SCEDULING\n",
    "        # Assign the task to the server\n",
    "        servers[server_id].append(tasks[n])\n",
    "\n",
    "        # Calculate completion time for the task\n",
    "        inter_arrival_time = tasks[n].arrival_time - inter_arrival_times[n - 1]\n",
    "        inter_arrival_times[n] = tasks[n].arrival_time\n",
    "        unfinished_work[server_id] = max(0, unfinished_work[server_id] - inter_arrival_time) + tasks[n].service_time\n",
    "        service_times.append(tasks[n].service_time)\n",
    "        task_completion_times[(tasks[n].job_id, tasks[n].task_id, tasks[n].arrival_time, tasks[n].cpu_usage)] = tasks[n].arrival_time + unfinished_work[server_id]\n",
    "    \n",
    "        message_loads += 1  # Increase the message load for each task assignment\n",
    "\n",
    "    mean_message_load = message_loads / len(tasks)  # Compute average message load\n",
    "\n",
    "        \n",
    "    return task_completion_times, service_times, mean_message_load\n",
    "\n",
    "\n",
    "import heapq\n",
    "\n",
    "# Function to simulate LWS dispatching and JSN scheduling\n",
    "def calculate_completion_time_SJN(tasks, num_servers):\n",
    "    servers = [[] for _ in range(num_servers)]\n",
    "    unfinished_work = [0] * num_servers\n",
    "    inter_arrival_times = [0] * len(tasks)\n",
    "    task_completion_times = {}\n",
    "    service_times = []\n",
    "    message_loads = 0\n",
    "\n",
    "    # Use a priority queue to order tasks by shortest job next (SJN)\n",
    "    task_queue = []\n",
    "    for n in range(len(tasks)):\n",
    "        heapq.heappush(task_queue, (tasks[n].arrival_time, tasks[n].service_time, tasks[n]))\n",
    "\n",
    "    while task_queue:\n",
    "        # Get the next task with the shortest remaining service time\n",
    "        _, _, task = heapq.heappop(task_queue)\n",
    "\n",
    "        # LWL DISPATCHING \n",
    "        available_servers = [i for i, server_tasks in enumerate(servers) if not server_tasks]  # Find servers with no tasks\n",
    "        if available_servers:\n",
    "            server_id = available_servers[0]  # Choose the first available server\n",
    "        else:\n",
    "            server_id = unfinished_work.index(min(unfinished_work))  # Find the server with the least unfinished work\n",
    "\n",
    "        # Assign the task to the server\n",
    "        servers[server_id].append(task)\n",
    "\n",
    "        # Calculate completion time for the task\n",
    "        inter_arrival_time = task.arrival_time - inter_arrival_times[n - 1]\n",
    "        inter_arrival_times[n] = task.arrival_time\n",
    "        unfinished_work[server_id] = max(0, unfinished_work[server_id] - inter_arrival_time) + task.service_time\n",
    "        service_times.append(task.service_time)\n",
    "        task_completion_times[(task.job_id, task.task_id, task.arrival_time, task.cpu_usage)] = unfinished_work[server_id]\n",
    "        \n",
    "        message_loads += 1  # Increase the message load for each task assignment\n",
    "\n",
    "    mean_message_load = message_loads / len(tasks)  # Compute average message load\n",
    "\n",
    "\n",
    "    return task_completion_times, service_times, mean_message_load\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff1e1f16",
   "metadata": {},
   "source": [
    "## Dispatching Algorithm\n",
    "\n",
    "\n",
    "LWL (Least Work Left) assigns the processing resource to the process or job with the least amount of remaining work, reducing the waiting time for processing and thus the mean job response time.\n",
    "\n",
    "In LWL scheduling, the system keeps track of the remaining work or workload of each process or job. When a resource becomes available, LWL selects the process or job with the smallest amount of unfinished work and allocates the resource to it. This approach aims to minimize the time required to complete each job and reduce overall response times.\n",
    "\n",
    "By prioritizing the processes or jobs with less work left, LWL can effectively distribute resources and ensure that jobs are processed more efficiently. This helps to decrease the waiting time for each job, leading to a reduction in the mean job response time.\n",
    "\n",
    "\n",
    "## Scheduling Algorithm \n",
    "\n",
    "Among the two scheduling policies, FCFS (First-Come, First-Served) and SJN (Shortest Job Next), the SJN policy generally tends to minimize the mean job response time compared to FCFS.\n",
    "\n",
    "Here's an explanation of the two scheduling policies:\n",
    "\n",
    "1. FCFS (First-Come, First-Served):\n",
    "\n",
    "- The FCFS algorithm processes requests based on their arrival order, assigning servers to them sequentially.\n",
    "- Requests are served one after another, without considering their duration or job complexity.\n",
    "- If a long-duration request is processed before a shorter one, the overall response time for requests can increase because the shorter requests have to wait longer.\n",
    "\n",
    "2. SJN (Shortest Job Next):\n",
    "\n",
    "- The SJN algorithm prioritizes requests based on their expected or estimated duration.\n",
    "- When a new request arrives, the SJN algorithm selects the request with the shortest duration and processes it first.\n",
    "- This approach reduces the overall response time as shorter requests are served quickly, thus reducing the wait time for other requests.\n",
    "\n",
    "In general, the SJN policy is considered more efficient than FCFS in minimizing the mean job response time since it prioritizes shorter requests that require less processing time. This helps reduce the overall waiting time and improve the average response time for requests.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2b390890",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the dataset and create Task objects\n",
    "tasks = []\n",
    "for index, row in tasks_dataframe.iterrows():\n",
    "    job_id = int(row[0])\n",
    "    task_id = int(row[1])\n",
    "    arrival_time = float(row[2])\n",
    "    cpu_usage = float(row[3])\n",
    "    memory_usage = float(row[4])\n",
    "    \n",
    "    task = Task(job_id, task_id, arrival_time, cpu_usage, memory_usage)\n",
    "    tasks.append(task)\n",
    "\n",
    "        \n",
    "# Calculate completion time for each task\n",
    "N = 64\n",
    "\n",
    "# Simulate baseline (LWL dispatching and FCFS scheduling)\n",
    "completion_times_baseline, service_times_baseline, mean_message_load_baseline = calculate_completion_time_baseline(tasks, N)\n",
    "\n",
    "# Simulate LWL dispatching and SJN scheduling\n",
    "completion_times_SJN, service_times_SJN, mean_message_load_SJN = calculate_completion_time_SJN(tasks, N)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a2fa32c",
   "metadata": {},
   "source": [
    "# 3. Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e35646b9",
   "metadata": {},
   "source": [
    "## 3.1 Job response time R"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03e8c2bb",
   "metadata": {},
   "source": [
    "Time elapsing since the arrival of the first arriving task of a job until all tasks belonging to that job\n",
    "have been fully served. The mean job response time R is obtained by averaging response times of all jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6d4695ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job Mean Response Time R of the baseline: 3772276.438344625\n",
      "Job Mean Response Time R of our algorithms: 80.01622684033926\n"
     ]
    }
   ],
   "source": [
    "job_response_times_baseline = {}\n",
    "for (job_id, task_id, arrival_time, cpu_usage), completion_time in completion_times_baseline.items():\n",
    "    if job_id not in job_response_times_baseline:\n",
    "        job_response_times_baseline[job_id] = completion_time\n",
    "    else:\n",
    "        job_response_times_baseline[job_id] += completion_time\n",
    "        \n",
    "job_response_time_baseline = sum(job_response_times_baseline.values())\n",
    "job_mean_response_time_baseline = job_response_time_baseline/len(job_response_times_baseline.values())\n",
    "print(\"Job Mean Response Time R of the baseline:\" , job_mean_response_time_baseline)\n",
    "\n",
    "\n",
    "job_response_times_SJN = {}\n",
    "for (job_id, task_id, arrival_time, cpu_usage), completion_time in completion_times_SJN.items():\n",
    "    if job_id not in job_response_times_SJN:\n",
    "        job_response_times_SJN[job_id] = completion_time\n",
    "    else:\n",
    "        job_response_times_SJN[job_id] += completion_time\n",
    "        \n",
    "job_response_time_SJN = sum(job_response_times_SJN.values())\n",
    "job_mean_response_time_SJN = job_response_time_SJN/len(job_response_times_SJN.values())\n",
    "print(\"Job Mean Response Time R of our algorithms:\", job_mean_response_time_SJN)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79e26750",
   "metadata": {},
   "source": [
    "## 3.2 Job slowdown S"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8adb8dd",
   "metadata": {},
   "source": [
    "Ratio of response time of the job to the sum of service times of all tasks belonging to the job. The\n",
    "mean job slowdown S is obtained by averaging slowdown values of all jobs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1ca886d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job Slowdown S of the baseline:  47143.89302399442\n",
      "Job Slowdown S of our algorithms:  1.0\n"
     ]
    }
   ],
   "source": [
    "job_slowdown_S_baseline = job_response_time_baseline/sum(service_times_baseline)\n",
    "print(\"Job Slowdown S of the baseline: \", job_slowdown_S_baseline)\n",
    "\n",
    "job_slowdown_S_SJN = job_response_time_SJN/sum(service_times_SJN)\n",
    "print(\"Job Slowdown S of our algorithms: \", job_slowdown_S_SJN)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae3aa1aa",
   "metadata": {},
   "source": [
    "# 3.3 Utilization coefficient of server  k, ρk "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fc7bea6",
   "metadata": {},
   "source": [
    "Fraction of time that the server k is busy serving tasks. The overall mean utilization coefficient is ρ = (ρ1 + · · · + ρN)/N.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2c721111",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Utilization of the baselien: 46519.07090246972\n",
      " \n",
      "Mean Utilization of our algorithms: 46519.070902469706\n"
     ]
    }
   ],
   "source": [
    "# DA RIVEDERE, probabilmente non è corretta\n",
    "total_simulation_time = 31\n",
    "utilizations_baseline = [service_time / total_simulation_time for service_time in service_times_baseline]\n",
    "mean_utilization_baseline = sum(utilizations_baseline) / 64\n",
    "#display(pd.DataFrame(utilizations_baseline))\n",
    "print(\"Mean Utilization of the baselien:\", mean_utilization_baseline)\n",
    "\n",
    "print(\" \")\n",
    "\n",
    "total_simulation_time = 31\n",
    "utilizations_SJN = [service_time / total_simulation_time for service_time in service_times_SJN]\n",
    "mean_utilization_SJN = sum(utilizations_SJN) / 64\n",
    "#print(utilizations_SJN)\n",
    "print(\"Mean Utilization of our algorithms:\", mean_utilization_SJN)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad4fc60d",
   "metadata": {},
   "source": [
    "# 3.4 Messaging load L"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4583e82",
   "metadata": {},
   "source": [
    "Number of messages exchanged between the dispatcher and servers for a given task dispatching. The\n",
    "mean message load L is obtained by averaging message load values of all tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8ca9bcbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Message Load of the baselien: 1.0\n",
      "\n",
      "Mean Message Load of our algorithms: 1.0\n"
     ]
    }
   ],
   "source": [
    "print(\"Mean Message Load of the baselien:\", mean_message_load_baseline)\n",
    "print()\n",
    "print(\"Mean Message Load of our algorithms:\", mean_message_load_SJN)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "04a4814d",
   "metadata": {},
   "source": [
    "# 4. Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "893f19e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job ID: 0, Task ID: 0, Arrival Time : 0, CPU : 1.5,  Completion Time: 15.0\n",
      "Job ID: 0, Task ID: 1, Arrival Time : 2, CPU : 2.2,  Completion Time: 24.0\n",
      "Job ID: 1, Task ID: 1, Arrival Time : 3, CPU : 0.8,  Completion Time: 25.0\n",
      "Job ID: 2, Task ID: 0, Arrival Time : 4, CPU : 3.0,  Completion Time: 55.0\n"
     ]
    }
   ],
   "source": [
    "######ESEMPIO######\n",
    "tasks_2 = [Task(0, 0, 0, 1.5, 0.3),\n",
    "         Task(0, 1, 2, 2.2, 0.5),\n",
    "         Task(1, 1, 3, 0.8, 0.7),\n",
    "         Task(2, 0, 4, 3.0, 0.9)]\n",
    "            \n",
    "    \n",
    "µ = 0.1\n",
    "N = 2\n",
    "completion_times, service_times, mean_message_load = calculate_completion_time_baseline(tasks_2, N)\n",
    "\n",
    "# Print completion time for each task\n",
    "for (job_id, task_id, arrival_time, cpu_usage), completion_time in completion_times.items():\n",
    "    print(f\"Job ID: {job_id}, Task ID: {task_id}, Arrival Time : {arrival_time}, CPU : {cpu_usage},  Completion Time: {completion_time}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "42eeed84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39.666666666666664"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job_response_times = {}\n",
    "for (job_id, task_id, arrival_time, cpu_usage), completion_time in completion_times.items():\n",
    "    if job_id not in job_response_times:\n",
    "        job_response_times[job_id] = completion_time\n",
    "    else:\n",
    "        job_response_times[job_id] += completion_time\n",
    "        \n",
    "job_response_time = sum(job_response_times.values())\n",
    "job_mean_response_time = job_response_time/len(job_response_times.values())\n",
    "job_mean_response_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "eb22b4a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.5866666666666667"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job_slowdown_S = job_response_time/sum(service_times)\n",
    "job_slowdown_S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a55524e3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
